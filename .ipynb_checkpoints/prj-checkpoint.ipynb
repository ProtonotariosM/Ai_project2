{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a string from positive reviews and find the 10 most frequent words\n",
    "#create a string from negative reviews and find the 10 most frequent words\n",
    "\n",
    "#those words will form the vector that will decide in which category a review should be stored in\n",
    "\n",
    "\n",
    "#each review will be represented by a vector(list) of these words, in each position the vector will have 0 or 1 for \"contained\" or \"not-contained\" respectivel\n",
    "#in each vector there will be an 11th position that will have 0 or 1 representing the category the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive reviews:  12500\n",
      "Total negative reviews:  12500\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "#DO THE SAME FOR THE NEGATIVE REVIEWS TO CHOOSE THE MOST COMMON WORDS BETWEEN ALL THE DATA \n",
    "#THEN FIND THE POSSIBILITY OF A WORD EXISTING IN POSITIVE AND THEN IN NEGATIVE REVIEWS, CALCULATE THE IG OF EACH WORD AND SORT THEM WITH DESCENDING IG VALUE\n",
    "\n",
    "\n",
    "files_positive = Path('/Users/michail/Downloads/aclImdb/train/pos').glob('*.txt')\n",
    "files_negative = Path('/Users/michail/Downloads/aclImdb/train/neg').glob('*.txt')\n",
    "\n",
    "#print(files)\n",
    "\n",
    "total_pos=0\n",
    "total_neg=0\n",
    "\n",
    "text= \"\"\n",
    "i=0\n",
    "for file in files_positive:\n",
    "    #print(file.name)\n",
    "    \n",
    "    text= text+file.read_text()  # the file is opened and closed\n",
    "    total_pos += 1\n",
    "    \"\"\"\n",
    "    i+=1\n",
    "    if i==500:\n",
    "        break\n",
    "    \"\"\"    \n",
    "\n",
    "    \n",
    "    \n",
    "for file in files_negative:\n",
    "    #print(file.name)\n",
    "    \n",
    "    total_neg+=1\n",
    "    text= text+file.read_text()  \n",
    "    \n",
    "\n",
    "print(\"Total positive reviews: \",  total_pos)\n",
    "print(\"Total negative reviews: \", total_neg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . much\n",
      "2 . other\n",
      "3 . people\n",
      "4 . bad\n",
      "5 . great\n",
      "6 . most\n",
      "7 . first\n",
      "8 . made\n",
      "9 . well\n",
      "10 . make\n",
      "11 . could\n",
      "12 . them\n",
      "13 . way\n",
      "14 . any\n",
      "15 . don't\n",
      "16 . too\n",
      "17 . think\n",
      "18 . movies\n",
      "19 . characters\n",
      "20 . films\n",
      "21 . seen\n",
      "22 . character\n",
      "23 . being\n",
      "24 . many\n",
      "25 . watch\n",
      "26 . two\n",
      "27 . \n",
      "28 . never\n",
      "29 . acting\n",
      "30 . plot\n",
      "31 . little\n",
      "32 . after\n",
      "33 . know\n",
      "34 . did\n",
      "35 . best\n",
      "36 . does\n",
      "37 . love\n",
      "38 . show\n",
      "39 . life\n",
      "40 . ever\n",
      "41 . better\n",
      "42 . off\n",
      "43 . over\n",
      "44 . say\n",
      "45 . end\n",
      "46 . scene\n",
      "47 . still\n",
      "48 . scenes\n",
      "49 . such\n",
      "50 . should\n",
      "51 . through\n",
      "52 . something\n",
      "53 . go\n",
      "54 . here\n",
      "55 . back\n",
      "56 . doesn't\n",
      "57 . real\n",
      "58 . thing\n",
      "59 . didn't\n",
      "60 . watching\n",
      "61 . man\n",
      "62 . I'm\n",
      "63 . years\n",
      "64 . actors\n",
      "65 . makes\n",
      "66 . find\n",
      "67 . work\n",
      "68 . few\n",
      "69 . actually\n",
      "70 . going\n",
      "71 . same\n",
      "72 . though\n",
      "73 . funny\n",
      "74 . lot\n",
      "75 . before\n",
      "76 . while\n",
      "77 . old\n",
      "78 . look\n",
      "79 . why\n",
      "80 . nothing\n",
      "81 . part\n",
      "82 . another\n",
      "83 . cast\n",
      "84 . quite\n",
      "85 . want\n",
      "86 . seems\n",
      "87 . &\n",
      "88 . pretty\n",
      "89 . got\n",
      "90 . every\n",
      "91 . fact\n",
      "92 . around\n",
      "93 . can't\n",
      "94 . things\n",
      "95 . again\n",
      "96 . enough\n",
      "97 . between\n",
      "98 . director\n",
      "99 . thought\n",
      "100 . own\n",
      "101 . take\n",
      "102 . young\n",
      "103 . give\n",
      "104 . original\n",
      "105 . gets\n",
      "106 . us\n",
      "107 . may\n",
      "108 . always\n",
      "109 . isn't\n",
      "110 . now\n",
      "111 . least\n",
      "112 . saw\n",
      "113 . whole\n",
      "114 . role\n",
      "115 . series\n",
      "116 . without\n",
      "117 . horror\n",
      "118 . new\n",
      "119 . I've\n",
      "120 . long\n",
      "121 . both\n",
      "122 . bit\n",
      "123 . interesting\n",
      "124 . almost\n",
      "125 . must\n",
      "126 . action\n",
      "127 . times\n",
      "128 . come\n",
      "129 . world\n",
      "130 . point\n",
      "131 . done\n",
      "132 . right\n",
      "133 . might\n",
      "134 . script\n",
      "135 . feel\n",
      "136 . big\n",
      "137 . family\n",
      "138 . comedy\n",
      "139 . anything\n",
      "140 . minutes\n",
      "141 . performance\n",
      "142 . far\n",
      "143 . music\n",
      "144 . am\n",
      "145 . probably\n",
      "146 . guy\n",
      "147 . kind\n",
      "148 . last\n",
      "149 . rather\n",
      "150 . found\n",
      "151 . since\n",
      "152 . away\n",
      "153 . played\n",
      "154 . making\n",
      "155 . that's\n",
      "156 . worst\n",
      "157 . comes\n",
      "158 . TV\n",
      "159 . fun\n",
      "160 . course\n",
      "161 . woman\n",
      "162 . trying\n",
      "163 . believe\n",
      "164 . each\n",
      "165 . goes\n",
      "166 . girl\n",
      "167 . looks\n",
      "168 . our\n",
      "169 . different\n",
      "170 . put\n",
      "171 . hard\n",
      "172 . shows\n",
      "173 . especially\n",
      "174 . yet\n",
      "175 . reason\n",
      "176 . main\n",
      "177 . sure\n",
      "178 . plays\n",
      "179 . watched\n",
      "180 . place\n",
      "181 . anyone\n",
      "182 . having\n",
      "183 . sense\n",
      "184 . seem\n",
      "185 . looking\n",
      "186 . takes\n",
      "187 . set\n",
      "188 . book\n",
      "189 . ending\n",
      "190 . worth\n",
      "191 . said\n",
      "192 . job\n",
      "193 . When\n",
      "194 . money\n",
      "195 . screen\n",
      "196 . actor\n",
      "197 . 2\n",
      "198 . himself\n",
      "199 . DVD\n",
      "200 . John\n",
      "201 . play\n",
      "202 . effects\n",
      "203 . together\n",
      "204 . One\n",
      "205 . day\n",
      "206 . version\n",
      "207 . true\n",
      "208 . someone\n",
      "209 . beautiful\n",
      "210 . left\n",
      "211 . audience\n",
      "212 . American\n",
      "213 . idea\n",
      "214 . However\n",
      "215 . three\n",
      "216 . All\n",
      "217 . special\n",
      "218 . during\n",
      "219 . wife\n",
      "220 . seeing\n",
      "221 . everything\n",
      "222 . excellent\n",
      "223 . Not\n",
      "224 . simply\n",
      "225 . shot\n",
      "226 . later\n",
      "227 . nice\n",
      "228 . once\n",
      "229 . completely\n",
      "230 . read\n",
      "231 . help\n",
      "232 . used\n",
      "233 . less\n",
      "234 . fan\n",
      "235 . you're\n",
      "236 . else\n",
      "237 . everyone\n",
      "238 . use\n",
      "239 . need\n",
      "240 . rest\n",
      "241 . performances\n",
      "242 . given\n",
      "243 . try\n",
      "244 . poor\n",
      "245 . year\n",
      "246 . short\n",
      "247 . mind\n",
      "248 . until\n",
      "249 . father\n",
      "250 . second\n",
      "251 . Hollywood\n",
      "252 . truly\n",
      "253 . tell\n",
      "254 . enjoy\n",
      "255 . 10\n",
      "256 . half\n",
      "257 . recommend\n",
      "258 . came\n",
      "259 . couple\n",
      "260 . either\n",
      "261 . kids\n",
      "262 . high\n",
      "263 . start\n",
      "264 . understand\n",
      "265 . production\n",
      "266 . home\n",
      "267 . boring\n",
      "268 . classic\n",
      "269 . friends\n",
      "270 . getting\n",
      "271 . mean\n",
      "272 . gives\n",
      "273 . moments\n",
      "274 . women\n",
      "275 . Even\n",
      "276 . along\n",
      "277 . playing\n",
      "278 . line\n",
      "279 . camera\n",
      "280 . remember\n",
      "281 . wrong\n",
      "282 . become\n",
      "283 . stupid\n",
      "284 . keep\n",
      "285 . small\n",
      "286 . doing\n",
      "287 . men\n",
      "288 . although\n",
      "289 . episode\n",
      "290 . wonderful\n",
      "291 . often\n",
      "292 . felt\n",
      "293 . death\n",
      "294 . however\n",
      "295 . supposed\n",
      "296 . instead\n",
      "297 . liked\n",
      "298 . awful\n",
      "299 . night\n",
      "300 . piece\n",
      "301 . terrible\n",
      "302 . dialogue\n",
      "303 . next\n",
      "304 . early\n",
      "305 . house\n",
      "306 . lines\n",
      "307 . itself\n",
      "308 . couldn't\n",
      "309 . maybe\n",
      "310 . person\n",
      "311 . sex\n",
      "312 . entire\n",
      "313 . full\n",
      "314 . perfect\n",
      "315 . went\n",
      "316 . against\n",
      "317 . name\n",
      "318 . human\n",
      "319 . others\n",
      "320 . sort\n",
      "321 . video\n",
      "322 . face\n",
      "323 . let\n",
      "324 . waste\n",
      "325 . budget\n",
      "326 . case\n",
      "327 . black\n",
      "328 . absolutely\n",
      "329 . definitely\n",
      "330 . style\n",
      "331 . becomes\n",
      "332 . problem\n",
      "333 . head\n",
      "334 . top\n",
      "335 . school\n",
      "336 . written\n",
      "337 . seemed\n",
      "338 . stars\n",
      "339 . title\n",
      "340 . certainly\n",
      "341 . After\n",
      "342 . Â–\n",
      "343 . already\n",
      "344 . entertaining\n",
      "345 . beginning\n",
      "346 . wanted\n",
      "347 . several\n",
      "348 . live\n",
      "349 . Well\n",
      "350 . 3\n",
      "351 . While\n",
      "352 . example\n",
      "353 . loved\n",
      "354 . hope\n",
      "355 . worse\n",
      "356 . lives\n",
      "357 . care\n",
      "358 . wants\n",
      "359 . I'd\n",
      "360 . tries\n",
      "361 . turn\n",
      "362 . fine\n",
      "363 . friend\n",
      "364 . totally\n",
      "365 . picture\n",
      "366 . direction\n",
      "367 . star\n",
      "368 . based\n",
      "369 . lead\n",
      "370 . laugh\n",
      "371 . Michael\n",
      "372 . able\n",
      "373 . called\n",
      "374 . lost\n",
      "375 . works\n",
      "376 . enjoyed\n",
      "377 . humor\n",
      "378 . fans\n",
      "379 . writing\n",
      "380 . turns\n",
      "381 . finally\n",
      "382 . war\n",
      "383 . gave\n",
      "384 . low\n",
      "385 . guess\n",
      "386 . past\n",
      "387 . drama\n",
      "388 . children\n",
      "389 . starts\n",
      "390 . throughout\n",
      "391 . sound\n",
      "392 . cinema\n",
      "393 . mother\n",
      "394 . quality\n",
      "395 . New\n",
      "396 . favorite\n",
      "397 . won't\n",
      "398 . amazing\n",
      "399 . under\n",
      "400 . guys\n",
      "401 . boy\n",
      "402 . final\n",
      "403 . behind\n",
      "404 . Now\n",
      "405 . viewer\n",
      "406 . evil\n",
      "407 . history\n",
      "408 . 1\n",
      "409 . parts\n",
      "410 . dead\n",
      "411 . son\n",
      "412 . perhaps\n",
      "413 . expect\n",
      "414 . themselves\n",
      "415 . car\n",
      "416 . side\n",
      "417 . killer\n",
      "418 . act\n",
      "419 . she's\n",
      "420 . feeling\n",
      "421 . game\n",
      "422 . decent\n",
      "423 . took\n",
      "424 . flick\n",
      "425 . stories\n",
      "426 . myself\n",
      "427 . says\n",
      "428 . town\n",
      "429 . actress\n",
      "430 . heard\n",
      "431 . cannot\n",
      "432 . you'll\n",
      "433 . late\n",
      "434 . genre\n",
      "435 . thinking\n",
      "436 . horrible\n",
      "437 . brilliant\n",
      "438 . directed\n",
      "439 . killed\n",
      "440 . days\n",
      "441 . kill\n",
      "442 . they're\n",
      "443 . Why\n",
      "444 . moment\n",
      "445 . matter\n",
      "446 . happens\n",
      "447 . fight\n",
      "448 . hand\n",
      "449 . girls\n",
      "450 . roles\n",
      "451 . dark\n",
      "452 . white\n",
      "453 . stuff\n",
      "454 . lack\n",
      "455 . attempt\n",
      "456 . film's\n",
      "457 . child\n",
      "458 . obvious\n",
      "459 . involved\n",
      "460 . extremely\n",
      "461 . told\n",
      "462 . heart\n",
      "463 . Just\n",
      "464 . particularly\n",
      "465 . eyes\n",
      "466 . including\n",
      "467 . leave\n",
      "468 . close\n",
      "469 . James\n",
      "470 . wouldn't\n",
      "471 . run\n",
      "472 . looked\n",
      "473 . etc\n",
      "474 . hour\n",
      "475 . complete\n",
      "476 . strong\n",
      "477 . group\n",
      "478 . obviously\n",
      "479 . art\n",
      "480 . Don't\n",
      "481 . sometimes\n",
      "482 . shown\n",
      "483 . voice\n",
      "484 . type\n",
      "485 . except\n",
      "486 . whose\n",
      "487 . violence\n",
      "488 . wonder\n",
      "489 . soon\n",
      "490 . interest\n",
      "491 . highly\n",
      "492 . daughter\n",
      "493 . kid\n",
      "494 . ago\n",
      "495 . chance\n",
      "496 . happened\n",
      "497 . experience\n",
      "498 . number\n",
      "499 . taken\n",
      "500 . coming\n",
      "501 . slow\n",
      "502 . itbr\n",
      "503 . somewhat\n",
      "504 . exactly\n",
      "505 . score\n",
      "506 . finds\n",
      "507 . happen\n",
      "508 . David\n",
      "509 . known\n",
      "510 . serious\n",
      "511 . relationship\n",
      "512 . started\n",
      "513 . annoying\n",
      "514 . simple\n",
      "515 . across\n",
      "516 . opening\n",
      "517 . usual\n",
      "518 . musical\n",
      "519 . career\n",
      "520 . despite\n",
      "521 . ends\n",
      "522 . hours\n",
      "523 . cinematography\n",
      "524 . hit\n",
      "525 . shots\n",
      "526 . save\n",
      "527 . released\n",
      "528 . stop\n",
      "529 . change\n",
      "530 . saying\n",
      "531 . jokes\n",
      "532 . novel\n",
      "533 . female\n",
      "534 . Robert\n",
      "535 . sad\n",
      "536 . ridiculous\n",
      "537 . huge\n",
      "538 . police\n",
      "539 . brother\n",
      "540 . English\n",
      "541 . episodes\n",
      "542 . living\n",
      "543 . turned\n",
      "544 . running\n",
      "545 . usually\n",
      "546 . talking\n",
      "547 . wish\n",
      "548 . alone\n",
      "549 . yourself\n",
      "550 . tells\n",
      "551 . reality\n",
      "552 . murder\n",
      "553 . Although\n",
      "554 . important\n",
      "555 . opinion\n",
      "556 . hilarious\n",
      "557 . ones\n",
      "558 . husband\n",
      "559 . knew\n",
      "560 . events\n",
      "561 . British\n",
      "562 . possible\n",
      "563 . mostly\n",
      "564 . local\n",
      "565 . taking\n",
      "566 . song\n",
      "567 . single\n",
      "568 . 4\n",
      "569 . I'll\n",
      "570 . order\n",
      "571 . level\n",
      "572 . body\n",
      "573 . due\n",
      "574 . aren't\n",
      "575 . age\n",
      "576 . documentary\n",
      "577 . songs\n",
      "578 . talent\n",
      "579 . call\n",
      "580 . sequence\n",
      "581 . gore\n",
      "582 . attention\n",
      "583 . view\n",
      "584 . problems\n",
      "585 . easily\n",
      "586 . supporting\n",
      "587 . Oh\n",
      "588 . major\n",
      "589 . crap\n",
      "590 . cool\n",
      "591 . bring\n",
      "592 . sets\n",
      "593 . moviebr\n",
      "594 . clearly\n",
      "595 . appears\n",
      "596 . similar\n",
      "597 . silly\n",
      "598 . word\n",
      "599 . knows\n",
      "600 . scary\n",
      "601 . That's\n",
      "602 . needs\n",
      "603 . falls\n",
      "604 . cut\n",
      "605 . Paul\n",
      "606 . cheap\n",
      "607 . strange\n",
      "608 . hero\n",
      "609 . today\n",
      "610 . giving\n",
      "611 . modern\n",
      "612 . 5\n",
      "613 . words\n",
      "614 . blood\n",
      "615 . Jack\n",
      "616 . romantic\n",
      "617 . mention\n",
      "618 . comic\n",
      "619 . predictable\n",
      "620 . feels\n",
      "621 . George\n",
      "622 . Unfortunately\n",
      "623 . light\n",
      "624 . Richard\n",
      "625 . room\n",
      "626 . television\n",
      "627 . Maybe\n",
      "628 . happy\n",
      "629 . filmbr\n",
      "630 . actual\n",
      "631 . message\n",
      "632 . surprised\n",
      "633 . enjoyable\n",
      "634 . haven't\n",
      "635 . future\n",
      "636 . nearly\n",
      "637 . disappointed\n",
      "638 . herself\n",
      "639 . points\n",
      "640 . named\n",
      "641 . within\n",
      "642 . bunch\n",
      "643 . theme\n",
      "644 . moving\n",
      "645 . review\n",
      "646 . above\n",
      "647 . Man\n",
      "648 . beyond\n",
      "649 . ways\n",
      "650 . elements\n",
      "651 . animation\n",
      "652 . upon\n",
      "653 . tried\n",
      "654 . showing\n",
      "655 . begins\n",
      "656 . First\n",
      "657 . none\n",
      "658 . seriously\n",
      "659 . typical\n",
      "660 . York\n",
      "661 . clear\n",
      "662 . storyline\n",
      "663 . overall\n",
      "664 . talk\n",
      "665 . From\n",
      "666 . comments\n",
      "667 . means\n",
      "668 . country\n",
      "669 . kept\n",
      "670 . dull\n",
      "671 . using\n",
      "672 . OK\n",
      "673 . four\n",
      "674 . certain\n",
      "675 . brought\n",
      "676 . Yes\n",
      "677 . entertainment\n",
      "678 . middle\n",
      "679 . leads\n",
      "680 . hell\n",
      "681 . Peter\n",
      "682 . dialog\n",
      "683 . working\n",
      "684 . thriller\n",
      "685 . famous\n",
      "686 . effort\n",
      "687 . near\n",
      "688 . power\n",
      "689 . fall\n",
      "690 . writer\n",
      "691 . easy\n",
      "692 . whether\n",
      "693 . viewers\n",
      "694 . form\n",
      "695 . figure\n",
      "696 . doubt\n",
      "697 . particular\n",
      "698 . release\n",
      "699 . team\n",
      "700 . sequel\n",
      "701 . five\n",
      "702 . hear\n",
      "703 . fantastic\n",
      "704 . among\n",
      "705 . weak\n",
      "706 . soundtrack\n",
      "707 . tale\n",
      "708 . theater\n",
      "709 . hate\n",
      "710 . greatest\n",
      "711 . material\n",
      "712 . decided\n",
      "713 . atmosphere\n",
      "714 . editing\n",
      "715 . realistic\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer\n",
    "import math\n",
    "from decimal import *\n",
    "\n",
    "split_it = text.split()\n",
    "bad_chars = [';', ':',\" \", \"!\", \"*\", \"(\", \")\", '\\\"', \".\", \",\", \"/\", \">\", \"<\"]\n",
    "\n",
    "for i in range(len(split_it)):\n",
    "    for b in bad_chars:\n",
    "        if b in split_it[i]:\n",
    "            split_it[i] = split_it[i].replace(b, '')\n",
    "\n",
    "\n",
    "Counters_found = Counter(split_it)\n",
    "most_occur = Counters_found.most_common(1000)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"The table with the most common words: \")\n",
    "print(most_occur)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "ps = PorterStemmer()\n",
    "words=[]\n",
    "for i in range(len(most_occur)):\n",
    "    words.append(most_occur[i][0])\n",
    "        \n",
    "\n",
    "\n",
    "words_to_exclude = ['-', '--', ';', ':', \"!\", \"*\", \" \", \"(\", \")\", '\\\"', \".\", 'it\\'s', 'br', 'mr', 'there\\'s', 'your', 'wasn\\'t', 'Ms', 'can', 'do', 'were', 'how', 'get', 'will', 'also', 'been', 'some', 'into', 'because', 'about', 'out', 'me', 'up', 'down', 'my', 'mine', 'their', 'she', 'he\\'s', 'the','you', 'an', 'his', 'him', 'her', 'or', 'was', 'have', 'has', 'had', 'in', 'i', 'he', 'we', 'they', 'their', 'theirs', 'which','what', 'where', 'be', 'they', 'has', 'so',  'by', 'who', 'that','this', 'those', 'your', 'these', 'on', 'there', 'and', 'to', 'a', 'it', 'its', 'for', 'if', 'then', 'is', 'at', 'are', 'of', 'no', 'as', 'but', 'with', 'there']    \n",
    "\n",
    "words_final=[]\n",
    "for i, w in enumerate(words):\n",
    "    \n",
    "    #print(\" w is: \" + w)\n",
    "    \n",
    "    for b in bad_chars:\n",
    "        if b in words[i]:\n",
    "            words[i]= words[i].replace(b,'')\n",
    "            w=words[i]\n",
    "        \n",
    "    \n",
    "    #print(\"Reading the word \" + words[i])\n",
    "    \n",
    "    \n",
    "    if w.lower() in words_to_exclude:\n",
    "        #print('removing ' +w)\n",
    "        #words.remove(w)\n",
    "        continue\n",
    "\n",
    "    words_final.append(words[i])        \n",
    "        \n",
    "\n",
    "\n",
    "words_final= words_final[20:len(words_final)-148]\n",
    "        \n",
    "        \n",
    "c=1\n",
    "for i in  words_final:\n",
    "    print(c,'. '+i)\n",
    "    c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_float(float_number, decimal_places):\n",
    "    multiplier = 10 ** decimal_places\n",
    "    return int(float_number * multiplier) / multiplier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IG(w, total_pos, total_neg):\n",
    "    total_reviews= total_pos + total_neg\n",
    "    \n",
    "    files_positive = Path('/Users/michail/Downloads/aclImdb/train/pos').glob('*.txt')\n",
    "    files_negative = Path('/Users/michail/Downloads/aclImdb/train/neg').glob('*.txt')\n",
    "    \n",
    "    \n",
    "    P1= (total_pos/total_reviews)  #probability of positive reviews\n",
    "    P0= (total_neg/total_reviews)  #probability of negative reviews\n",
    "    \n",
    "    entropy= -P1*math.log2(P1)-P0*math.log2(P0)\n",
    "    #print(\"Total entropy: \", entropy)\n",
    "    \n",
    "\n",
    "    \n",
    "    #print (\"Entropy is: \", entropy)\n",
    "    \n",
    "    #Probabilities of C=pos and w=1 & C=neg and w=1\n",
    "    pos_counter=0\n",
    "    neg_counter=0 \n",
    "    total_counter=0\n",
    "    \n",
    "    \n",
    "    for f in files_positive:\n",
    "        if w in f.read_text():\n",
    "            #print(\"it's in positive: \", w)\n",
    "            pos_counter+=1\n",
    "            total_counter+=1\n",
    "      \n",
    "    for f in files_negative:\n",
    "        if w in f.read_text():\n",
    "            #print(\"it's in negative: \", w)\n",
    "            neg_counter+=1\n",
    "            total_counter+=1\n",
    "    \n",
    "    \n",
    "    #Probability of w=1 and w=0 \n",
    "    P_w1 = total_counter/total_reviews\n",
    "    #print(\"Probability of \", w, \"=1: \", P_w1)\n",
    "    P_w0 = (total_reviews- total_counter) / total_reviews\n",
    "    #print(\"Probability of \", w, \"=0: \", P_w0)\n",
    "\n",
    "        \n",
    "   \n",
    "    #Probability of a C=pos and C=neg when w=1\n",
    "    if P_w1!=0:\n",
    "        P1_w1= pos_counter/total_counter \n",
    "        #print(\"probability positive reviews with \", w,\"=1: \", P1_w1)\n",
    "        P0_w1= neg_counter/total_counter\n",
    "        #print(\"probability negative reviews with \", w,\"=1: \", P0_w1)\n",
    "    else:\n",
    "        P1_w1=0\n",
    "        P0_w1=0\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Probability of a C=pos and C=neg when w=0\n",
    "    if P_w0!=0:\n",
    "        P1_w0 = (total_pos-pos_counter)/(total_reviews- total_counter)\n",
    "        #print(\"probability positive reviews with \", w,\"=0: \", P1_w0)\n",
    "        P0_w0 = (total_neg-neg_counter)/(total_reviews - total_counter)\n",
    "        #print(\"probability positive reviews with \", w,\"=0: \", P0_w0)\n",
    "    else:\n",
    "        P1_w0 = 0\n",
    "        P0_w0 = 0\n",
    "    \n",
    "    \n",
    "    entropy_w1= (0 if P1_w1==0 else -P1_w1*math.log2(P1_w1)) - (0 if P0_w1==0 else P0_w1*math.log2(P0_w1))\n",
    "    #print(\"Entropy of \", w, \"=1: \", entropy_w1)\n",
    "    entropy_w0= (0 if P1_w0==0 else -P1_w0*math.log2(P1_w0)) - (0 if P0_w0==0 else P0_w0*math.log2(P0_w0))\n",
    "    #print(\"Entropy of \", w, \"=0: \", entropy_w0)\n",
    "\n",
    "    \n",
    "    if entropy!=1.0:\n",
    "        ig= truncate_float(entropy, 6) - truncate_float((P_w1*entropy_w1 + P_w0*entropy_w0), 6)\n",
    "        \"\"\"\"\n",
    "        print(\"Truncated P_w1: \", truncate_float(P_w1*entropy_w1, 4))\n",
    "        print(\"Truncated P_w0: \", truncate_float(P_w0*entropy_w0, 4))\n",
    "        print(\"Truncated entropy: \", truncate_float(entropy,4))\n",
    "        \"\"\"\n",
    "    else:\n",
    "        getcontext().prec = 6\n",
    "        ig= Decimal(1) - Decimal((P_w1*entropy_w1 + P_w0*entropy_w0))\n",
    "        \n",
    "        \"\"\"\"\n",
    "        print(\"Decimal P_w1: \", Decimal(P_w1*entropy_w1))\n",
    "        print(\"Decimal P_w0: \", Decimal(P_w0*entropy_w0))\n",
    "        print(\"Decimal entropy: \", Decimal(entropy))                        \n",
    "        \"\"\"\n",
    "        \n",
    "      \n",
    "    \n",
    "    #print(\"IG type: \", type(ig))\n",
    "    \n",
    "    \n",
    "    #print (\"IG type is: (\", entropy, \") - (\", P_w1, \"*\", entropy_w1, \" + \",P_w0, \"*\", entropy_w0,\")\")\n",
    "    \n",
    "    \n",
    "    print(\"IG of \",w , \"is: \", ig)\n",
    "    \n",
    "    return float(ig)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IG of  boring is:  0.0162208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0162208"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig= IG(\"boring\", total_pos, total_neg)\n",
    "ig  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE IG IN EVERY WORD OF THE ARRAY\n",
    "def words_with_IG(words_final):\n",
    "    words_IG={}\n",
    "\n",
    "    for w in words_final:\n",
    "        ig= IG(w, total_pos, total_neg)\n",
    "        if ig>=0.005:\n",
    "            words_IG[w]= ig\n",
    "            #words_IG.append(IG(w, total_pos, total_neg))\n",
    "            print(\"\\n\",words_IG ,\"\\n\")\n",
    "            \n",
    "    return words_IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_IG(words_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
